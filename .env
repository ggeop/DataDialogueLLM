# Backend Settings
MODEL_REPO=lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF
MODEL_FILE=Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf
MODEL_LOCAL_DIR=/
API_HOST=0.0.0.0
API_PORT=8000
MAX_TOKENS=1000

# Frontend Settings
LLM_BACKEND_URL=http://backend:8000/generate

# Docker Settings
COMPOSE_PROJECT_NAME=data-dialogue

# Development Settings
NODE_ENV=development
FLASK_ENV=development
FLASK_DEBUG=1